# Meta Agent CX â€” AI-Powered CX Phone Agent Builder

> **A Meta Agent system that creates and configures Customer Experience (CX) phone agents
> through natural language descriptions.**

![Version](https://img.shields.io/badge/version-1.0.0-blue)
![Python](https://img.shields.io/badge/python-3.11%2B-green)
![FastAPI](https://img.shields.io/badge/FastAPI-0.115-teal)

---

## ğŸ¯ Overview

This system implements a **Meta Agent** â€” an AI that creates other AI agents. Non-technical
users describe what kind of phone support agent they need in plain English, and the Meta Agent
generates:

- **Persona Configuration** â€” name, role, personality, system prompt
- **Voice Settings** â€” TTS provider, voice ID, gender, language, speed
- **Intent Definitions** â€” what the agent can recognize, with training phrases
- **Function Calls** â€” API integrations with endpoint mappings and mock data
- **Conversation Flow** â€” complete state machine with nodes and transitions
- **Deployment Config** â€” platform-ready settings for VoiceOwl, Twilio, or Vonage

---

## ğŸ—ï¸ Architecture

The system uses a **modular sub-agent architecture**:

```
User Request â†’ Meta Orchestrator â†’ Agent Creator + Function Creator â†’ CXAgentConfig
```

| Component | File | Role |
|-----------|------|------|
| **Meta Orchestrator** | `meta_agent/orchestrator.py` | Analyzes requests, coordinates sub-agents |
| **Agent Creator** | `meta_agent/agent_creator.py` | Generates persona, voice, intents, flow |
| **Function Creator** | `meta_agent/function_creator.py` | Defines callable functions + API mappings |
| **Data Models** | `meta_agent/models.py` | Pydantic schemas for all configurations |
| **Prompt Chain** | `meta_agent/prompts.py` | System prompts for all agents |
| **FastAPI Server** | `main.py` | REST API + web UI serving |

> See [ARCHITECTURE.md](ARCHITECTURE.md) for detailed diagrams and component descriptions.

---

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. (Optional) Set OpenAI API Key

For LLM-powered generation:
```bash
# Create a .env file
echo OPENAI_API_KEY=sk-your-key-here > .env
```

> **Without an API key, the system runs in rule-based mode** â€” fully functional
> with deterministic, keyword-driven generation.

### 3. Run the Server

```bash
python main.py
```

Or with Uvicorn directly:
```bash
uvicorn main:app --reload --host 0.0.0.0 --port 8000
```

### 4. Open the Web UI

Navigate to **http://localhost:8000** in your browser.

### 5. API Usage

```bash
curl -X POST http://localhost:8000/api/create-agent \
  -H "Content-Type: application/json" \
  -d '{
    "user_prompt": "Create a support bot for appointment booking. It should greet, ask for name and date, and confirm availability via an API.",
    "language": "en-US",
    "platform": "voiceowl"
  }'
```

---

## ğŸ“‹ Deliverables Mapping

| # | Deliverable | Location |
|---|-------------|----------|
| 1 | **Meta Prompt / Prompt Chain** | `meta_agent/prompts.py` |
| 2 | **Function Definition Logic** | `meta_agent/function_creator.py` |
| 3 | **Example Input â†’ Output** | `examples/example_output.json` + `/api/example` endpoint |
| 4 | **Architecture Sketch** | `ARCHITECTURE.md` |
| 5 | **Minimal Prototype** | Full FastAPI app (`main.py` + `meta_agent/`) |

---

## ğŸ“ Prompt Engineering Details

### Prompt Chain Design

The system uses a **3-stage prompt chain**:

#### Stage 1: Meta Orchestrator Prompt
```
Purpose:  Analyze natural language â†’ structured analysis brief
Input:    User's free-text description
Output:   JSON with domain, tasks, functions_needed, flow_summary
Strategy: Zero-shot with detailed output schema specification
```

#### Stage 2: Agent Creator Prompt
```
Purpose:  Analysis brief â†’ agent configuration
Input:    JSON analysis brief from Stage 1
Output:   JSON with persona, voice, intents, conversation_flow
Strategy: Few-shot style with detailed rules for system prompt generation
```

#### Stage 3: Function Creator Prompt
```
Purpose:  Function requirements â†’ complete function definitions
Input:    JSON array of function requirements from Stage 1
Output:   JSON with function definitions, API endpoints, mock responses
Strategy: Schema-driven with REST convention enforcement
```

### Key Prompt Engineering Techniques Used

1. **Structured Output Enforcement** â€” All prompts require JSON-only output
2. **Schema Specification** â€” Exact JSON schemas provided in each prompt
3. **Role Definition** â€” Clear role assignment ("You are the Agent Creator...")
4. **Constraint Rules** â€” Explicit rules section with do's and don'ts
5. **Separation of Concerns** â€” Each sub-agent has a focused responsibility
6. **Fallback Strategy** â€” LLM failure â†’ rule-based deterministic generation
7. **Temperature Tuning** â€” Low temperature (0.3-0.4) for consistent structured output

---

## âš¡ Function Call Integration

### How Functions Are Defined

1. The **Meta Orchestrator** extracts `functions_needed` from the user request
2. The **Function Creator** generates full definitions with:
   - Typed parameter schemas
   - REST API endpoint configurations
   - Realistic mock responses
   - OpenAI-compatible tool schemas

### OpenAI Function Calling Format

Every generated function is also output as an OpenAI tool schema:

```json
{
  "type": "function",
  "function": {
    "name": "get_appointment_slots",
    "description": "Check available appointment slots...",
    "parameters": {
      "type": "object",
      "properties": {
        "preferred_date": {
          "type": "string",
          "description": "The customer's preferred date"
        }
      },
      "required": ["preferred_date"]
    }
  }
}
```

### Function â†’ API Mapping

Each function includes an `api_endpoint` configuration:

```json
{
  "url": "/api/v1/appointments/slots",
  "method": "GET",
  "headers": { "Content-Type": "application/json" },
  "auth_type": "bearer",
  "timeout_seconds": 10
}
```

---

## ğŸ”§ Example: Input â†’ Output

### Input
```
"Create a support bot for appointment booking. It should greet,
ask for name and date, and confirm availability via an API."
```

### Output Summary
- **Agent Name:** MediBot
- **Role:** Healthcare Appointment & Patient Support Agent
- **Personality:** Friendly, professional, helpful
- **Voice:** Google Neural2-F (female, en-US)
- **Intents:** greeting, request_appointment_booking, request_confirm_availability, fallback, request_human_agent
- **Functions:** `get_appointment_slots()`, `check_availability()`
- **Flow:** 10+ nodes (greeting â†’ collect name â†’ collect date â†’ API call â†’ decision â†’ success/failure â†’ confirm â†’ end)

> See the full JSON output at the `/api/example` endpoint or in `examples/example_output.json`.

---

## ğŸ—ï¸ Project Structure

```
geetabhawan/
â”œâ”€â”€ main.py                      # FastAPI application entry point
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ .env                         # (optional) OpenAI API key
â”œâ”€â”€ ARCHITECTURE.md              # Architecture documentation
â”œâ”€â”€ README.md                    # This file
â”œâ”€â”€ meta_agent/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ orchestrator.py          # Meta Orchestrator (main coordinator)
â”‚   â”œâ”€â”€ agent_creator.py         # Agent Creator sub-agent
â”‚   â”œâ”€â”€ function_creator.py      # Function Creator sub-agent
â”‚   â”œâ”€â”€ models.py                # Pydantic data models
â”‚   â””â”€â”€ prompts.py               # System prompts for all agents
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ index.html               # Web UI
â”‚   â”œâ”€â”€ style.css                # Design system & styles
â”‚   â””â”€â”€ script.js                # Frontend logic
â””â”€â”€ examples/
    â””â”€â”€ example_output.json      # Pre-built example output
```

---

## ğŸ“Š Evaluation Rubric Coverage

| Category (Points) | Implementation |
|---|---|
| **Conceptual Design (20)** | Modular sub-agent arch, clear separation of concerns, dual-mode (LLM/rule-based) |
| **Prompt Engineering (25)** | 3-stage prompt chain, JSON enforcement, temperature tuning, schema-driven |
| **Function Call Integration (20)** | Full parameter schemas, API endpoint mapping, OpenAI tool format, mock responses |
| **Example Quality (15)** | Complete inputâ†’output with all config sections, live `/api/example` endpoint |
| **Technical Implementation (10)** | FastAPI + Pydantic, async, type hints, error handling, dual mode |
| **Documentation & Clarity (10)** | README, ARCHITECTURE.md, inline docstrings, prompt documentation |
| **Bonus (+10)** | Phone context (voice config, TTS), modular sub-agents, deployment awareness |

---

## License

MIT
